/**
 * @file Defines the interface for an LLM (Large Language Model) service.
 * This allows for abstraction over different LLM providers or models.
 */

/**
 * Represents the payload required to generate a code suggestion using an LLM.
 */
export interface LlmPromptPayload {
  /** The original comment from the reviewer that prompted the suggestion. */
  reviewerComment: string;
  /** The relevant code context (e.g., surrounding lines, diff hunk) for the suggestion. */
  codeContext: string;
  /** Optional project-specific rules or guidelines to be considered by the LLM. */
  projectRules?: string;
  /** Optional. The programming language of the codeContext. This can help the LLM provide more accurate suggestions. */
  language?: string;
  /** Optional. The file path where the code exists, for additional context. */
  filePath?: string;
}

/**
 * Represents a code suggestion generated by the LLM.
 */
export interface LlmSuggestion {
  /** The suggested code change, formatted as a GitHub suggestion markdown block. */
  suggestionMarkdown: string;
  /** An optional brief rationale or explanation for the suggested change. */
  rationale?: string;
  /** Optional. Any error message if the suggestion generation failed. */
  error?: string;
}

/**
 * Defines the contract for interacting with an LLM to generate code suggestions.
 */
export interface LlmService {
  /**
   * Generates a code suggestion based on the provided payload.
   * @param payload - The input data required by the LLM to generate a suggestion.
   * @returns A promise that resolves to the LLM-generated suggestion.
   */
  generateSuggestion(payload: LlmPromptPayload): Promise<LlmSuggestion>;
}
